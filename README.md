# ğŸ›‘ Stop Sign Detection and Distance Estimation using Stereo Vision and YOLO

## ğŸ“Œ Overview

This project implements a robust and efficient system for **real-time stop sign detection and distance estimation** using a combination of deep learning (YOLO) and classical stereo vision techniques.

Developed with **affordability and high performance** in mind, this solution is ideal for applications in autonomous driving, advanced driver-assistance systems (ADAS), and robotics â€” where accurate environmental perception is critical.

Unlike traditional object detection systems that only identify objects, this project leverages **stereoscopic triangulation** to provide precise depth information, giving vehicles or robots a crucial understanding of their surroundings in 3D space.

---

## ğŸš€ Key Features & Advantages

- **Hybrid Approach for Enhanced Perception**  
  Combines YOLO for real-time object detection with Stereo Vision for precise distance estimation.

- **High Detection Accuracy**  
  The YOLO model achieves **over 80%** accuracy in detecting stop signs, even in complex scenes.

- **Accurate Distance Estimation**  
  Uses the `Stereo SGBM (Semi-Global Block Matching)` algorithm to compute disparity maps and apply the triangulation formula:  
  `Z = (f Ã— B) / d`

- **Cost-Effective Alternative**  
  Requires only stereo cameras â€” making it significantly cheaper than LIDAR or RADAR.

- **Rich Visual Data**  
  Unlike LIDAR or RADAR, stereo cameras offer full-color and texture-rich images, enabling deeper scene understanding.

- **Real-Time Performance**  
  Efficient YOLO inference + optimized stereo algorithms enable fast processing.

- **Modular and Maintainable Codebase**  
  Built around the `StereoYOLOProcessor` class for clarity, modularity, and ease of future updates.

---

## âš™ï¸ Technical Details

### ğŸ” Models and Algorithms

- **YOLO (You Only Look Once)** â€“ Fast and accurate object detection for bounding boxes and labels.
- **Stereo SGBM (Semi-Global Block Matching)** â€“ Computes pixel-wise disparity between stereo pairs.
- **Triangulation Formula** â€“ Converts disparity to distance:  
  `Z = (focal_length Ã— baseline) / disparity`

### ğŸ“¸ How It Works

1. **Stereo Image Capture** â€“ Left and right frames are captured from a calibrated stereo camera pair.  
2. **Image Rectification** â€“ Aligns images along epipolar lines to prepare for matching.  
3. **Stop Sign Detection (YOLO)** â€“ YOLO processes one image (typically left) to detect and localize stop signs.  
4. **Disparity Map Generation (SGBM)** â€“ Disparity computed from stereo image pair using SGBM.  
5. **Distance Estimation** â€“ The average disparity inside the bounding box is used to calculate the distance.

---

## ğŸ“ Project Structure

```
STOP_SIGN_PYTHON/
â”œâ”€â”€ .pycache__/
â”œâ”€â”€ .venv/                      # Python virtual environment
â”œâ”€â”€ extracted_tesla_frames/     # Processed or raw frame data
â”œâ”€â”€ STOP_LEFT_frames/           # Left image frames
â”œâ”€â”€ STOP_RIGHT_frames/          # Right image frames
â”œâ”€â”€ scene0/
â”œâ”€â”€ scene1/
â”œâ”€â”€ video/
â”‚   â”œâ”€â”€ LEFT.mp4
â”‚   â””â”€â”€ RIGHT.mp4
â”œâ”€â”€ config.txt                  # Configuration (model paths, thresholds, etc.)
â”œâ”€â”€ detection.py                # Main processing script (detection + depth)
â”œâ”€â”€ last.pt                     # YOLO model weights
â”œâ”€â”€ packages.py                 # Custom modules
â”œâ”€â”€ README.md                   # This file
â””â”€â”€ video.py                    # Video capture/processing
.gitattributes
.gitignore
```

> **Note:** The main class `StereoYOLOProcessor` is likely defined in `detection.py`.

---

## ğŸ› ï¸ Getting Started

### 1ï¸âƒ£ Prerequisites

Make sure the following are installed:

- Python 3.8+
- Git

### 2ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/HodayaMoyal/Streo_Stop_Sign.git
cd STOP_SIGN_PYTHON
```

### 3ï¸âƒ£ Create a Virtual Environment

```bash
python -m venv .venv
```

### 4ï¸âƒ£ Activate the Environment

**Windows:**

```bash
.\.venv\Scripts\activate
```

**macOS/Linux:**

```bash
source ./.venv/bin/activate
```

### 5ï¸âƒ£ Install Dependencies

If you have a `requirements.txt`:

```bash
pip install -r requirements.txt
```

Otherwise, install manually:

```bash
pip install opencv-python numpy ultralytics configparser
```

### 6ï¸âƒ£ Download Models and Calibration Files

Ensure the following:

- `last.pt` (YOLO weights) is in the project root.
- `camera_calibration.yml` is available (with intrinsic/extrinsic params).

> If not calibrated yet â€” see the **Calibration** section.

### 7ï¸âƒ£ Configure `config.txt`

Update settings such as:

```
model_path=last.pt
confidence_threshold=0.5
calibration_file=camera_calibration.yml
num_disparities=64
block_size=11
```

### 8ï¸âƒ£ Run the Project

Run the main script:

```bash
python detection.py
```

> The script will output detected stop signs, bounding boxes, and estimated distances. You can optionally modify it to save output frames.

---

## ğŸ§ª Calibration

Stereo calibration is essential. Use OpenCVâ€™s calibration tools or a dedicated script (e.g., `calibrate.py`) to generate `camera_calibration.yml`.

---

## ğŸ¤ Contributing

We welcome contributions!

```bash
# Fork and clone
git checkout -b feature/my-feature
# Make your changes
git commit -m "Add new feature"
git push origin feature/my-feature
# Open a Pull Request
```

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the `LICENSE` file for details.
